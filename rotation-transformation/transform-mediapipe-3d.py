# PoC of using three angles to transform the finger path by mediapipe
# Instability because of z-coordinate generated by mediapipe
# Angle calculation needs fixes

import cv2
import numpy as np
import mediapipe as mp

# Initialize Mediapipe Hands shorter
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(max_num_hands=1, min_detection_confidence=0.5, min_tracking_confidence=0.5)

# Test data rotation angles
angle_x = 70  # Rotation angle around the x-axis
angle_y = 20  # Rotation angle around the y-axis
angle_z = -20  # Rotation angle around the z-axis

angle_x_rad = np.radians(angle_x)
angle_y_rad = np.radians(angle_y)
angle_z_rad = np.radians(angle_z)

# Rotation matrix for x-rotation
R_x = np.array([
    [1, 0, 0],
    [0, np.cos(angle_x_rad), -np.sin(angle_x_rad)],
    [0, np.sin(angle_x_rad), np.cos(angle_x_rad)]
])

# Rotation matrix for y-rotation
R_y = np.array([
    [np.cos(angle_y_rad), 0, np.sin(angle_y_rad)],
    [0, 1, 0],
    [-np.sin(angle_y_rad), 0, np.cos(angle_y_rad)]
])

# Rotation matrix for z-rotation
R_z = np.array([
    [np.cos(angle_z_rad), -np.sin(angle_z_rad), 0],
    [np.sin(angle_z_rad), np.cos(angle_z_rad), 0],
    [0, 0, 1]
])

# Combined rotation matrix
R = np.dot(R_z, np.dot(R_y, R_x))



def draw_path(image, path, color=(255, 0, 0)):
    for i in range(len(path) - 1):
        start_point = (int(path[i][0]), int(path[i][1]))
        end_point = (int(path[i + 1][0]), int(path[i + 1][1]))
        cv2.line(image, start_point, end_point, color, 2)
    for point in path:
        cv2.circle(image, (int(point[0]), int(point[1])), 5, color, -1)



cap = cv2.VideoCapture(0)
image_size = (500, 500, 3)
original_image = np.ones(image_size, dtype=np.uint8) * 255
transformed_image = np.ones(image_size, dtype=np.uint8) * 255

finger_path = []

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    results = hands.process(frame_rgb)

    if results.multi_hand_landmarks:
        for hand_landmarks in results.multi_hand_landmarks:
            thumb_tip = hand_landmarks.landmark[4] # 4 = thumb
            h, w, _ = frame.shape
            x, y, z = thumb_tip.x * w, thumb_tip.y * h, thumb_tip.z
            print(f"Coordinates: x={x}, y={y}, z={z}")
            finger_path.append([x, y, z])

            mp.solutions.drawing_utils.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)

    # Apply the 3D rotation matrix to each point in the finger path
    if finger_path:
        finger_path_np = np.array(finger_path)
        transformed_finger_path = np.dot(finger_path_np, R.T)

        # Debugging
        print("Original Path:", finger_path_np)
        print("Transformed Path:", transformed_finger_path)

        # Shitty solution, but the path is often outside
        transformed_finger_path[:, 0] = np.clip(transformed_finger_path[:, 0], 0, image_size[1] - 1)
        transformed_finger_path[:, 1] = np.clip(transformed_finger_path[:, 1], 0, image_size[0] - 1)

        original_image.fill(255)
        transformed_image.fill(255)
        draw_path(original_image, finger_path_np, (255, 0, 0))
        draw_path(transformed_image, transformed_finger_path, (0, 0, 255))

        combined_image = np.hstack((original_image, transformed_image))

        cv2.imshow("Finger path transformation", combined_image)

    # Show original video with handmarks
    #cv2.imshow("Hand Tracking", frame)

    if cv2.waitKey(1) == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
hands.close()
